{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn import metric_spec\n",
    "from tensorflow.contrib.learn.python.learn.estimators import _sklearn\n",
    "from tensorflow.contrib.learn.python.learn.estimators import estimator\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.saved_model import loader\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.util import compat\n",
    "tf.logging.set_verbosity(tf.logging.FATAL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/alam/Downloads/New DAta/DataNew.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Creating the Target Label\n",
    "\n",
    "From a prior notebook, I examined the 'loan_status' column. The cell below creates a column with binary value 0 for loans not in default, and binary value 1 for loans in default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Default_Binary'] = int(0)\n",
    "for index, value in data.Credit_History.iteritems():\n",
    "    if value == 'Default':\n",
    "        data.set_value(index,'Default_Binary',int(1))\n",
    "    if value == 'Charged Off':\n",
    "        data.set_value(index, 'Default_Binary',int(1))\n",
    "    if value == 'Late (31-120 days)':\n",
    "        data.set_value(index, 'Default_Binary',int(1))    \n",
    "    if value == 'Late (16-30 days)':\n",
    "        data.set_value(index, 'Default_Binary',int(1))\n",
    "    if value == 'Does not meet the credit policy. Status:Charged Off':\n",
    "        data.set_value(index, 'Default_Binary',int(1))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Creating a category feature for \"Loan Purpose\"\n",
    "\n",
    "Below I create a new column for loan purpose, and assign each type of loan purpose an integer value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Purpose_Cat'] = int(0) \n",
    "for index, value in data.Purpose_Credit_Taken.iteritems():\n",
    "    if value == 'Vehicle':\n",
    "        data.set_value(index,'Purpose_Cat',int(1))\n",
    "    if value == 'Furniture':\n",
    "        data.set_value(index, 'Purpose_Cat',int(2))\n",
    "    if value == 'Electronics Appliances':\n",
    "        data.set_value(index, 'Purpose_Cat',int(3))    \n",
    "    if value == 'Vacation':\n",
    "        data.set_value(index, 'Purpose_Cat',int(4))    \n",
    "    if value == 'Repairs':\n",
    "        data.set_value(index,'Purpose_Cat',int(5))\n",
    "    if value == 'Remodeling house':\n",
    "        data.set_value(index, 'Purpose_Cat',int(6))\n",
    "    if value == 'Education':\n",
    "        data.set_value(index, 'Purpose_Cat',int(7))    \n",
    "    if value == 'Training':\n",
    "        data.set_value(index, 'Purpose_Cat',int(8))   \n",
    "    if value == 'Business':\n",
    "        data.set_value(index, 'Purpose_Cat',int(9))    \n",
    "    if value == 'Others':\n",
    "        data.set_value(index,'Purpose_Cat',int(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Scaling Loan Amount\n",
    "\n",
    "Below I scale the amount funded for each loan to a value between 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.202982\n",
      "1    0.085012\n",
      "2    0.324254\n",
      "3    0.133432\n",
      "4    0.667932\n",
      "Name: Credit_Amount_scaled, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x = np.array(data.Credit_Amount.values).reshape(-1,1) \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "data['Credit_Amount_scaled'] = pd.DataFrame(x_scaled)\n",
    "print (data.Credit_Amount_scaled[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Scaling Number of Credit\n",
    "\n",
    "Below I scale the interest rate for each loan to a value between 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.333333\n",
      "1    0.333333\n",
      "2    0.333333\n",
      "3    0.000000\n",
      "4    0.000000\n",
      "Name: Num_Credits_scaled, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x = np.array(data.Num_Credits.values).reshape(-1,1) \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "data['Num_Credits_scaled'] = pd.DataFrame(x_scaled)\n",
    "print (data.Num_Credits_scaled[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setting up the Neural Network\n",
    "\n",
    "Below I split the data into a training, testing, and prediction set\n",
    "\n",
    "After that, I assign the feature and target columns, and create the function that will be used to pass the data into the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = data[0:3000] \n",
    "testing_set = data[3001:4000] \n",
    "prediction_set = data[4001:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLUMNS = ['Purpose_Cat','Credit_Amount_scaled','Num_Credits_scaled','Default_Binary']          \n",
    "FEATURES = ['Purpose_Cat','Credit_Amount_scaled','Num_Credits_scaled']\n",
    "LABEL = 'Default_Binary'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def input_fn(data_set):\n",
    "    feature_cols = {k: tf.constant(data_set[k].values) for k in FEATURES} \n",
    "    labels = tf.constant(data_set[LABEL].values)\n",
    "    return feature_cols, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting The Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNNRegressor(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x7f748ec12450>, 'hidden_units': [10, 20, 10], 'feature_columns': (_RealValuedColumn(column_name='Purpose_Cat', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='Credit_Amount_scaled', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='Num_Credits_scaled', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)), 'embedding_lr_multipliers': None, 'optimizer': None, 'dropout': None, 'gradient_clip_norm': None, 'activation_fn': <function relu at 0x7f74ac929d70>, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [tf.contrib.layers.real_valued_column(k)\n",
    "              for k in FEATURES]\n",
    "#config = tf.contrib.learn.RunConfig(keep_checkpoint_max=1) ######## DO NOT DELETE\n",
    "regressor = tf.contrib.learn.DNNRegressor(\n",
    "  feature_columns=feature_cols, hidden_units=[10, 20, 10], ) \n",
    "regressor.fit(input_fn=lambda: input_fn(training_set), steps=251)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.000024\n"
     ]
    }
   ],
   "source": [
    "# Score accuracy\n",
    "ev = regressor.evaluate(input_fn=lambda: input_fn(testing_set), steps=10)\n",
    "loss_score = ev[\"loss\"]\n",
    "print(\"Loss: {0:f}\".format(loss_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = regressor.predict(input_fn=lambda: input_fn(prediction_set))\n",
    "predictions = list(itertools.islice(y,1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
